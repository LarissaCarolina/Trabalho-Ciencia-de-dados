---
lang: pt-BR
output:
  pdf_document: default
  word_document: default
---

\begin{titlepage}
	\begin{center}
		\textbf{\LARGE{Universidade Federal de Minas Gerais}}\\
		\LARGE{Departamento de Estatística}\\ 
		\vspace{4cm}
        \vspace{100pt}
        \textbf{\LARGE{Relatório Final - Ciência de dados}}\\
		\vspace{3,5cm}
	\end{center}
	
	\begin{center}
			\textbf{Alunas:}\\ Amanda Xavier,\\ Ana Clara Orzil,\\ Larissa Carolina,\\ Letícia Canhestro e\\Natália Carolina \\
			\textbf{Professor:} Fábio Demarqui \\
 \end{center}
	\vspace{1cm}
	
	\begin{center}
		\vspace{\fill}
			 Agosto\\
		 2020
			\end{center}
\end{titlepage}


\newpage
\setcounter{tocdepth}{2}
\tableofcontents
\newpage




# Introdução
  Atualmente, estamos vivendo um surto de uma doença infecciosa chamada Covid-19 que é causada pelo novo coronavírus (Sars-Cov-2). A doença foi identificada pela primeira vez em Wuhan, na província de Hubei, República Popular da China.

  Em 11 de março de 2020, a Organização Mundial de Saúde (OMS) declarou que estamos enfrentando uma pandemia, devido à rápida disseminação geográfica que a doença apresentou.

  Apesar do mundo inteiro viver sob estado de alerta por essa doença, os países a enfrentam com  diferentes intensidades. Muitas razões podem ser atribuídas para esse fato, por exemplo os recursos que o países detêm para investimento em infraestura para o combate à doença, posicionamento dos governantes no sentido de fornecer à população condições para se protegerem, até mesmo a  postura da população em relação ao cumprimento das medidas de segurança, entre outros.

  A partir deste trabalho iremos fornecer uma visão sobre o panorama da doença atualmente. O produto final será um painél desenvolvido em shiny que trará análises descritivas visuais e métricas de interesse sobre o momento atual da pandemia no mundo e no Brasil.

  A fonte utilizada para a busca dos dados em nível mundial foi o repositório de dados sobre a Covid-19 administrado pela universidade Johns Hopkins (EUA), já para buscar dados em nível Brasil utilizamos o portal Coronavirus-Brasil gerenciado pelo Ministério da Saúde.

\newpage

# Manipulação dos dados
 Uma vez utilizadas fontes de dados diferentes, o processo de manipulação dos dados também ocorreu de maneira distinta nos dados referentes ao mundo e ao Brasil. Iremos detalhar a seguir cada um deles. Nesta etapa, as integrantes encarregadas deste tratamento foram Larissa Carolina e Letícia Canhestro nos dados do mundo e Ana Clara, Amanda Xavier e Natália Oliveira nos dados do Brasil.
 
## Dados do Mundo
   Uma vez utilizadas fontes de dados diferentes, o processo de manipulação dos dados também ocorreu de maneira distinta nos dados referentes ao mundo e ao Brasil. Iremos detalhar a seguir cada um deles. Nesta etapa, as integrantes encarregadas deste tratamento foram Larissa Carolina e Letícia Canhestro nos dados do mundo e Ana Clara, Amanda Xavier e Natália Oliveira nos dados do Brasil.

   Feito isso, precisamos juntar as três bases de maneira a obter uma única tabela com as informações desejadas. Isso foi feito utilizando a função de junção *left_join*, os atributos utilizados como chaves foram *Province/State*, *Country/Region*, *Lat* e *Long* que são comuns às três bases. Neste ponto, percebemos que algumas localidades estavam com informações diferentes nas três bases, para solucionar tal problema identificamos quais eram essas localidas e a tratamos de maneira diferenciada utilizando um data.frame auxiliar, por fim fizemos a união dos dados que se uniram certo aos que precisaram ser tratados separadamente.

   Ao juntar as bases, houve casos em que as informações dos três bancos estavam diferente.O Canadá, por exemplo, tem seus dados registrados no banco de confirmados e mortes por província, já no banco de recuperados a informação vem de forma única para o país. Assim, necessitamos unir os dados dos países em que os dados de mortes e/ou recuperados estavam sendo perdidas de forma separada e depois uní-los ao banco.

   Após isso, outras manipulações básicas foram feitas como por exemplo verificação da classe das colunas, adequação do tipo delas ao desejado (Ex.: Transformação da coluna de data para o formato date, isso foi feito utilizando a função *mdy* do pacote **lubridate**).

   Algo importante que nos demandou um cuidado especial no tratamento desses dados foi o fato de não existir a coluna que nos trouxesse as informações de novos casos, novos óbitos e novos recuperados. Pensamos em utilizar a função *diff* de maneira direta nos dados para obter essas informações. Porém, ao tentarmos percebemos que a informação do primerio registro não era retornada isso gerava inconsistência nos dados. Fizemos um outro teste utilizando uma manipulação com a função *lag* com o lag de um passo. Neste caso, o primeiro registro era retornado, porém com dado ausente, já que não havia valor disponível a ser subtraído do primeiro registro. Por fim, fizemos uma manipulação que utilizava a função *diff*, mas que agregava o primeiro valor de casos ao primeiro registro da coluna de novos (casos, óbitos ou recuperados) para cada país.

   Um outra etapa para a conclusão desse processo de manipulação dos dados foi necessário para a construção dos visuais de mapa. Para essa etapa, como estamos interessados em visualizar de maneira espacial o comportamento das métricas de interesse, achamos mais adequado não agrupar os territórios afastado ao seu país "dono". A união entre a base de dados da pandemia com a base que contem a geometria dos países foi feita pela latitude e longitude. Utilizamos a função *st_nearest_feature* do pacote **sf**.Ela vefifica a geometria mais próxima do ponto dado pela latitude e longitude informada. Como havia o risco de termos associado uma geometria a algum ponto de forma errônea,   utilizamos funções de manipulação de textos como a  *rm_acent* do pacote **abjutils** e outras funções como *str_replace* do pacote **stringr** para verificar se as geometrias obtidas correspondem aos territórios almejados.
   
## Dados do Brasil

  Como dito anteriormente, a fonte utilizada para buscar os dados referentes ao Brasil foi o portal do Ministério da Saúde.
  
  Para a leitura automática dos dados, foi necessário a criação de uma sequência de condições que conseguisse lidar com a constante mudança na extensão do arquivo que é disponibilizado no portal. Um passo anterior a isso foi a utilização da função *GET* do pacote ***httr* para obter a url exata para buscar o arquivo, a autenticação obtida através da ação de inspeção no site do portal foi necessária nesse passo.
  
  Agora sim, na construção da sequência de condições o nosso objetivo era identificar a extensão do arquivo retornado e a partir disso utilizar a função adequada para a leitura dos dados. Para identificar a extensão do arquivo foi utilizada a função *str_detect* do pacote **stringr** e para a leitura dos dados a função utilizada foi a *import* do pacote **rio**. Importante destacar aqui que a recomendação para a leitura dos dados dessa maneira foi apresentada durante as aulas da disciplina.
  
  A disposição dos dados segue de maneira segmentada por localidade, as primeiras linhas são os dados referentes ao Brasil como um todo desde o início da pandemia (25/02/2020) no país, seguidas das linhas referentes a cada um dos estados, por fim temos as linhas para o maior nível de detalhes que são os municípios por estado em cada data desde o início.
  
  Identificando isso, o nosso próximo passo foi a divisão da base em três novas bases que seriam de maior interesse para a análise, são elas dados_brasil (com os dados da pandemia no país ao longo dos dias), dados_estados (com os dados da pandemia nos estados ao longo dos dias) e por fim a base dados_municipios na mesma estrutura. Para essa tarefa, utilizamoso operador "%--%" para calcular o intervalo entre a data inicial da pandemia e a data atual, essa será a quantidade de repetição de linhas que teremos para cada uma das localidades. 
  
  Feito isso, utilizamos variáveis auxiliares para definir onde começa e termina a disposição dos dados por estado e assim obtivemos os dados_estados. Para os dados do país como um todo, percebemos que o valor da coluna *coduf* era sempre 76, assim foi necessário apenas filtrar por esse código para obter os dados_brasil (utilizando a função *filter* pacote **dplyr**). 
  
  Para obter os dados para os municípios de Minas Gerais, realizamos um filtro que selecionava as linhas onde o município era diferente de nulo e o estado era "MG".
  
  Um problema que percebemos ao logo da verificação dos resultados obtidos foi que as linhas referentes a Rondonia a nível de estado estavam repetidas, porém com todos os valores das colunas zerados. Dessa forma, foi necessário eliminar essas linhas para o nosso resultado final. 

\newpage

# Criação das visualizações

  As visualizações construídas foram as mesmas tanto para os dados do Mundo quanto para os dados do Brasil. Porém, detalharemos nesta sessão detalhes que foram particulares a cada um deles.
  
  Para a construção dos gráficos básicos utilizamos o pacote **ggplot2** e suas funções.
  
  As animações foram feitas utilizando o pacote **gganimate**. As animações criadas foram as seguintes:
  
1. Gráfico de corrida de barras para o total de casos confirmados ao longo do tempo;

2. Série de novos casos ao longo do tempo;

  Para a primeira, foi preciso pensar em uma forma de apresentar os resultados de maneira que o gráfico não ficasse com muitas informações e transmitisse de forma objetiva a informação desejada. Então, decidimos selecionar utilizando funções do pacote **dplyr** o top 6 dos locais (país ou estado) com o maior número de casos. Feito isso, criamos um rank a cada data desses locais, utilizamos a função *row_number()* nos dados agrupados por data. Isso foi necessário para que a cada mudança de data na animação os países ficassem ordenados de acordo ao total de casos, sendo possível visualizar facilmente a posição de cada país.
  
  A construção do gráfico foi feita com o uso do pacote **ggplot2** e sua estrutura. A função *transition_time* do pacote **gganimate** foi utilizada para determinar a variável de transição do gráfico e função *animate* também do mesmo pacote foi utilizada para estabelecer o número de frames e o tempo de pausa ao fim da animação.
  
  Para a segunda, selecionamos o top 2 dos locais com maior número de casos para acompanhar como se deu a série de número de novos casos desde o início da pandemia. A construção do gráfico e a animação seguiu a mesma ideia anterior, exceto pelo uso da função *transition_reveal* ao invés de *transition_time*.

  Para a construção dos mapas a nível mundial, descreveremos resumidamente os passo executados.
  
  Primeiro, utilizamos a função *ne_countries* do pacote **rnaturalearth** para obter os limites do países do mundo, as funções *st_as_sf* e  *st_set_crs* foram utilizadas para converter as logitudes e latitudes em coordenadas, essas funções fazem parte do pacote *sf*. Após isso, utilizamos a função *st_nearest_feature*, a ideia é pegar o polígono mais próximo de acordo com as geometrias construídas no passo anterior. Por fim, utilizamos a função *geom_sf* para construir os mapas utilizando a estrutura do pacote **ggplot2** e a função *ggplotly* do pacote **plotly** para tornar o mapa interativo.
  
  Para verificar se a junção foi realizada de maneira correta, fizemos alguns filtros e comparações para identificar essas diferenças. Além disso, fizemos uma verificação com os dados divulgados diariamente pelo Google Notícias com os casos da China, identificamos algumas diferenças e chegamos a realizar uma pesquisa para entender quais territórios eram considerados como parte do país, neste momento percebemos até uma inconscistência na soma desses casos pelo portal.
  
  Para a construção do mapa em nível Brasil, utilizamos o pacote **brmap**  para carregar e obter as geometrias dos estados. Filtramos nossos dados com informações de estado por uma data específica (que no painél será um filtro  a ser selecionado), a essa base filtrada juntamos (utilizando a função *left_join*) a geometria dos estados, a chave utilizada para essa junção foi a coluna *coduf* presente na base de dados do Brasil disponibilizada pelo Ministério da Saúde e a coluna *estado_cod* presente na base *brmap_estado* contida no pacote.
  
  Feito isso, o próximo passo foi a construção do mapa utilizando as funcionalidades e estrutura do pacote **ggplot2**. Assim como no mapa do mundo, a função *geom_sf* foi utilizada. Ao fim desse processo, foi utilizada a função **ggplotly** do pacote **plotly** para tornar o gráfico interativo.
  
   Para a construção das nuvens de palavras utilizamos o pacote **wordcloud2**. O principio básico da construção foi o mesmo para os dados do mundo e do Brasil, descreveremos o processo executado.
   
   Os dados utilizados na nuvem foram extraídos do Twitter através do pacote **twitteR**. Para poder acessar as informações do twitter através de sua API, foi necessário criar um aplicativo para que se possa obter quatro dados para autenticação: Consumer Key, Consumer Secret, Access Token e Access Secret. A criação desse aplicativo é realizada no site https://developer.twitter.com/en/apps. Com os dados da autenticação em mãos, podemos registrá-los no R com a função *setup_twitter_oauth*.
   
  Para a consulta no Twitter foi utilizada a função *searchTwitter*, onde filtramos os 1000 tweets mais recentes que citaram a palavra 'covid19'. O diferencial entre a nuvem do mundo e do Brasil é que no primeiro caso adicionamos o filtro de tweets realizados em inglês e no segundo o filtro da língua portuguesa.
  
  Para transformar os tweets em palavras separadas utilizamos a função *strsplit* do pacote **stringr**. Feito isso, realizamos alguns ajustes na lista de palavras para retirar pontuações, números e espaços, esses ajustes foram realizados através da função *tm_map* do pacote **tm**. Observamos que a lista de palavras obtida possuia uma grande quantidade de stop words, que são palavras que podem ser consideradas irrelevantes para os resultados como, por exemplo, os artigos. Novamente a função *tm_map* foi utilizada para retirar essas palavras do conjunto.
  
  O conjunto de palavras obtido após esses ajustes foi transformado em uma tabela de frequência e então representado visualmente na nuvem de palavras através da função *wordcloud2*.
  
\newpage
# Criação do painel

  O painel foi criado a partir do pacote **flexdashboard**. Ele permite a estruturação das visualizações em formato de dashboard de maneira bem simples, utilizando  o **RMarkdown**. Para incluir filtros dos dados, o pacote permite uma interação com o **shiny**.

  Nesta etapa, criamos funções reativas dos dados para que as visualizações fossem sensíveis aos filtros. Além disso, usamos a função  *ggplotly* do pacote **plotly** para que os gráficos e mapas fossem interativos e ocupassem a área gráfica da melhor forma possíviel. 

  Assim como em aplicativos shiny, textos, mapas e outros elementos reativos precisam ser renderizandos. Assim usamos as funções *renderValueBox* que renderiza os cartões (ou valueBox) e renderPlotly para os elementos do plotly. As funções do tipo *Input* do shiny, foram utilizadas para coleta dos parâmetros dos filtros ou seleção do tipo de informação para os mapas.

  As animações são os únicos elementos que não rodam junto com o aplicatvo. Elas foram salvas em formato de gif e então são lidas pelo painel. Esse procedimento foi necessário, pois essas visualizações gastam um tempo razóavel para carregar, causando lentidão no app. 

# Apêncice

## Crorograma do grupo

Iremos resumir aqui como nos organizamos ao longo do semestre para a exeucução do trabalho. De maneira geral, marcamos algumas reuniões com todas as integrantes do grupo e nelas decidimos quais seriam os próximos passos.

A seguir apresentaremos algumas notas importantes que fizemos em cada uma dessas reuniões.

### Reunião 22/08

Nosso produto final será um painel usando shiny.

Faremos mapas, cartões com os números de mortos, novos casos, etc...

Para próxima reunião: 

- Estudar o shiny.


### Reunião 12/09

Encontramos o flexdashboard. É um pacote onde utilizamos o Rmarkdown para criar paineis. É possível integrar com o shiny.  


A ideia inicial é ter 3 abas no painel:

1. Visão do mundo

2. Visão do Brasil

3. Visão de Minas

4. Se der tempo uma aba com o detalhamento de BH

**Ideias para tentativas**

- Nuvem de palavras (pacote wordcloud2) com tweets sobre a covid (Pacote que Ana e Natalia usaram na disciplina de Pacotes Estatísticos : twitteR)

- Gráfico de corrida de barras 

**Tarefa:**

Tentar automatizar a extração dos dados do portal do ministério da saúde.

### Reunião 26/09

- Não será mais necessário extrair os dados diretamente do portal do ministério da saúde. Podemos pegar do Rafael.

- 

**Tarefa:**

- Ver se é possível automatizar a atualização do painel. 

- Organizar os nossos scripts para subir para o github

## Atribuição de tarefas do grupo

Listaremos aqui um resumo de como funcionou a divisão de tarefas entre as integrantes do grupo.

1. Manipulação de dados (Mundo) : Letícia Canhestro e Larissa Carolina;

2. Manipulação de dados (Brasil) : Ana Clara, Amanda Xavier e Natália Caroline;

3. Visualizações

    - Métricas dos cartões: Natália Caroline;
    
    - Animações (Mundo e Brasil): Larissa Carolina;
    
    - Mapa (Brasil e Mundo): Amanda Xavier e Larissa Carolina; 

4. Montagem do painél: Ana Clara, Amanda Xavier e Letícia Canhestro;

5. Construção do relatório: Ana Clara, Amanda Xavier, Larissa Carolina, Letícia Canhestro e Natália Oliveira;

